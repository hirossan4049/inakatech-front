import { Container, Title, Text, Button, Stack, Group, TextInput, Textarea, Card, ActionIcon, Tooltip } from '@mantine/core';
import { notifications } from '@mantine/notifications';
import { IconDeviceFloppy, IconArrowLeft, IconMicrophone, IconMicrophoneOff } from '@tabler/icons-react';
import { useState, useEffect } from 'react';
import { useNavigate, useParams } from 'react-router-dom';
import { apiClient, type Tree } from '../api/client';
import { useMediaQuery } from '@mantine/hooks';

export default function JournalCreatePage() {
  const navigate = useNavigate();
  const { treeId } = useParams<{ treeId: string }>();
  const [tree, setTree] = useState<Tree | null>(null);
  const [content, setContent] = useState('');
  const [date, setDate] = useState(new Date().toISOString().split('T')[0]);
  const [loading, setLoading] = useState(false);
  const [treeLoading, setTreeLoading] = useState(true);
  const [isListening, setIsListening] = useState(false);
  const [recognition, setRecognition] = useState<SpeechRecognition | null>(null);
  const isMobile = useMediaQuery('(max-width: 768px)');

  useEffect(() => {
    const fetchTree = async () => {
      if (!treeId) return;

      try {
        setTreeLoading(true);
        const treeData = await apiClient.getTree(parseInt(treeId));
        setTree(treeData);
      } catch (error) {
        console.error('Failed to fetch tree:', error);
        notifications.show({
          title: 'ã‚¨ãƒ©ãƒ¼',
          message: 'æœ¨ã®ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ',
          color: 'red',
        });
      } finally {
        setTreeLoading(false);
      }
    };

    fetchTree();
  }, [treeId]);

  useEffect(() => {
    console.log('Speech Recognition Check:');
    console.log('window.SpeechRecognition:', 'SpeechRecognition' in window);
    console.log('window.webkitSpeechRecognition:', 'webkitSpeechRecognition' in window);
    console.log('navigator.userAgent:', navigator.userAgent);

    // Chrome ã¨ Firefox ä¸¡æ–¹ã«å¯¾å¿œ
    const globalWindow = window as typeof window & {
      SpeechRecognition?: typeof SpeechRecognition;
      webkitSpeechRecognition?: typeof SpeechRecognition;
    };

    globalWindow.SpeechRecognition = globalWindow.webkitSpeechRecognition || globalWindow.SpeechRecognition;

    if (globalWindow.SpeechRecognition) {
      console.log('Speech Recognition API available');
      try {
        const recognitionInstance = new globalWindow.SpeechRecognition();
        recognitionInstance.continuous = true;
        recognitionInstance.interimResults = true;
        recognitionInstance.lang = 'ja-JP';

        recognitionInstance.onresult = (event: SpeechRecognitionEvent) => {
          let finalTranscript = '';
          for (let i = event.resultIndex; i < event.results.length; i++) {
            if (event.results[i].isFinal) {
              finalTranscript += event.results[i][0].transcript;
            }
          }
          if (finalTranscript) {
            setContent(prev => prev + (prev ? ' ' : '') + finalTranscript);
          }
        };

        recognitionInstance.onerror = (event: SpeechRecognitionErrorEvent) => {
          console.error('Speech recognition error:', event.error);
          setIsListening(false);
          notifications.show({
            title: 'ã‚¨ãƒ©ãƒ¼',
            message: `éŸ³å£°èªè­˜ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: ${event.error}`,
            color: 'red',
          });
        };

        recognitionInstance.onend = () => {
          setIsListening(false);
        };

        setRecognition(recognitionInstance);
        console.log('Speech Recognition instance created successfully');
      } catch (error) {
        console.error('Failed to create Speech Recognition instance:', error);
      }
    } else {
      console.log('Speech Recognition API not available');
    }
  }, []);

  const handleSave = async () => {
    if (!treeId || !content.trim()) {
      notifications.show({
        title: 'ã‚¨ãƒ©ãƒ¼',
        message: 'ä½œæ¥­å†…å®¹ã¯å¿…é ˆã§ã™',
        color: 'red',
      });
      return;
    }

    setLoading(true);
    try {
      await apiClient.createWorkLog(parseInt(treeId), {
        date,
        description: content,
      });

      notifications.show({
        title: 'ä¿å­˜å®Œäº†',
        message: 'ä½œæ¥­æ—¥èªŒã‚’ä¿å­˜ã—ã¾ã—ãŸ',
        color: 'green',
      });

      navigate(`/tree/${treeId}`);
    } catch (error) {
      console.error('Failed to save work log:', error);
      notifications.show({
        title: 'ã‚¨ãƒ©ãƒ¼',
        message: 'ä½œæ¥­æ—¥èªŒã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ',
        color: 'red',
      });
    } finally {
      setLoading(false);
    }
  };

  const toggleVoiceInput = () => {
    console.log('toggleVoiceInput called, recognition:', !!recognition);

    if (!recognition) {
      const globalWindow = window as typeof window & {
        SpeechRecognition?: typeof SpeechRecognition;
      };
      console.log('SpeechRecognition available:', !!globalWindow.SpeechRecognition);

      let message = 'ã“ã®ãƒ–ãƒ©ã‚¦ã‚¶ã¯éŸ³å£°èªè­˜ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã›ã‚“ã€‚';

      if (location.protocol !== 'https:' && location.hostname !== 'localhost') {
        message += ' HTTPSãŒå¿…è¦ã§ã™ã€‚';
      }

      if (navigator.userAgent.includes('Firefox')) {
        message += ' Firefoxã§ã¯éŸ³å£°èªè­˜ãŒåˆ¶é™ã•ã‚Œã¦ã„ã¾ã™ã€‚Chromeã¾ãŸã¯Edgeã‚’æ¨å¥¨ã—ã¾ã™ã€‚';
      }

      notifications.show({
        title: 'ã‚¨ãƒ©ãƒ¼',
        message,
        color: 'red',
        autoClose: 5000,
      });
      return;
    }

    if (isListening) {
      console.log('Stopping speech recognition');
      recognition.stop();
      setIsListening(false);
    } else {
      console.log('Starting speech recognition');
      try {
        recognition.start();
        setIsListening(true);
      } catch (error) {
        console.error('Failed to start recognition:', error);
        notifications.show({
          title: 'ã‚¨ãƒ©ãƒ¼',
          message: 'éŸ³å£°èªè­˜ã®é–‹å§‹ã«å¤±æ•—ã—ã¾ã—ãŸ',
          color: 'red',
        });
      }
    }
  };

  return (
    <Container size={isMobile ? '100%' : 'md'} py="xl">
      <Stack gap="lg">
        <Group justify="space-between">
          <Title order={1}>æ–°è¦æ—¥èªŒä½œæˆ</Title>
          <Button
            variant="subtle"
            leftSection={<IconArrowLeft size={16} />}
            onClick={() => navigate(treeId ? `/tree/${treeId}` : '/dashboard')}
          >
            æˆ»ã‚‹
          </Button>
        </Group>

        <Text size="lg" c="dimmed">
          ç‰¹å®šã®æœ¨ã«å¯¾ã™ã‚‹ä½œæ¥­è¨˜éŒ²ã‚„è¦³å¯Ÿçµæœã‚’è¨˜éŒ²ã—ã¾ã—ã‚‡ã†ã€‚
        </Text>

        {treeLoading ? (
          <Text>èª­ã¿è¾¼ã¿ä¸­...</Text>
        ) : tree ? (
          <Card withBorder shadow="sm" padding="lg">
            <Stack gap="md">
              <Stack gap="xs">
                <Text fw={500}>å¯¾è±¡ã®æœ¨:</Text>
                <Text>{`æœ¨ #${tree.id} (${tree.type})`}</Text>
                <Text size="sm" c="dimmed">{`ç·¯åº¦: ${tree.lat.toFixed(4)}, çµŒåº¦: ${tree.lng.toFixed(4)}`}</Text>
              </Stack>

            <TextInput
              label="ä½œæ¥­æ—¥"
              type="date"
              required
              value={date}
              onChange={(event) => setDate(event.currentTarget.value)}
            />

            <Stack gap="xs">
              <Group justify="space-between" align="flex-end">
                <Text size="sm" fw={500}>
                  ä½œæ¥­å†…å®¹ <Text component="span" c="red">*</Text>
                </Text>
                {(recognition || (window as typeof window & { SpeechRecognition?: typeof SpeechRecognition }).SpeechRecognition) && (
                  <Tooltip label={isListening ? "éŸ³å£°å…¥åŠ›ã‚’åœæ­¢" : "éŸ³å£°å…¥åŠ›ã‚’é–‹å§‹"}>
                    <ActionIcon
                      variant={isListening ? "filled" : "light"}
                      color={isListening ? "red" : "blue"}
                      size="lg"
                      onClick={toggleVoiceInput}
                    >
                      {isListening ? <IconMicrophoneOff size={18} /> : <IconMicrophone size={18} />}
                    </ActionIcon>
                  </Tooltip>
                )}
              </Group>
              <Textarea
                placeholder="ä½œæ¥­å†…å®¹ã‚„è¦³å¯Ÿçµæœã‚’è©³ã—ãè¨˜éŒ²ã—ã¦ãã ã•ã„ï¼ˆéŸ³å£°å…¥åŠ›ã‚‚å¯èƒ½ã§ã™ï¼‰"
                required
                minRows={8}
                value={content}
                onChange={(event) => setContent(event.currentTarget.value)}
                style={{
                  border: isListening ? '2px solid #fa5252' : undefined,
                }}
              />
              {isListening && (
                <Text size="xs" c="red" ta="center">
                  ğŸ¤ éŸ³å£°ã‚’èªè­˜ä¸­...
                </Text>
              )}
            </Stack>

              <Group justify="flex-end">
                <Button
                  variant="filled"
                  color="green"
                  leftSection={<IconDeviceFloppy size={16} />}
                  onClick={handleSave}
                  loading={loading}
                >
                  ä¿å­˜
                </Button>
              </Group>
            </Stack>
          </Card>
        ) : (
          <Text c="red">æœ¨ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“</Text>
        )}
      </Stack>
    </Container>
  );
}